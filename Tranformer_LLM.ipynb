{
  "cells": [
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-04-20T10:30:19.511335Z",
          "start_time": "2025-04-20T10:30:14.130243Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:30:21.755678Z",
          "start_time": "2025-04-20T10:30:21.729677Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "420a4dfdadcdee66",
        "outputId": "a0132552-6de3-4c64-c3ab-73cdf858dbc0"
      },
      "cell_type": "code",
      "source": [
        "with open(\"/content/India, officially the Republic of I.txt\",'r',encoding='utf-8') as f:\n",
        "    raw_text=f.read()\n",
        "print(len(raw_text))\n",
        "print(raw_text[:100])"
      ],
      "id": "420a4dfdadcdee66",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55955\n",
            "India, officially the Republic of India,[j][21] is a country in South Asia. It is the seventh-larges\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Characters:\",len(raw_text))\n",
        "print(\"Total_tokens:\",len(tokenizer.encode(raw_text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAI3MquYj0NH",
        "outputId": "b639cbd4-377a-4fc6-cf0f-7da19331afef"
      },
      "id": "PAI3MquYj0NH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 55955\n",
            "Total_tokens: 12860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.9\n",
        "train_size = int(train_ratio * len(raw_text))\n",
        "train_text = raw_text[:train_size]\n",
        "val_text = raw_text[train_size:]"
      ],
      "metadata": {
        "id": "YJ4KwDtekrSy"
      },
      "id": "YJ4KwDtekrSy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iIF0xUq-Vb5",
        "outputId": "7270a964-d9e4-4ffd-b00f-2ec54533fe64"
      },
      "id": "5iIF0xUq-Vb5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:30:25.020010Z",
          "start_time": "2025-04-20T10:30:24.959908Z"
        },
        "id": "dd29070035dafb99"
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tiktoken\n",
        "\n",
        "class GPTTokenizerDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        token_ids = self.tokenizer.encode(txt)\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1:i + max_length+1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True):\n",
        "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    dataset = GPTTokenizerDataset(txt, tokenizer, max_length, stride)\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last\n",
        "    )\n",
        "    return dataloader"
      ],
      "id": "dd29070035dafb99",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:30:52.552634Z",
          "start_time": "2025-04-20T10:30:52.545337Z"
        },
        "id": "40a9c2660445b78c"
      },
      "cell_type": "code",
      "source": [
        "def generate_text(model,idx,max_new_tokens,context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond=idx[:,-context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits=model(idx_cond)\n",
        "        logits=logits[:,-1,:]\n",
        "        probas=torch.softmax(logits,dim=-1)\n",
        "        idx_next=torch.argmax(probas,dim=-1,keepdim=True)\n",
        "        idx=torch.cat((idx,idx_next),dim=1)\n",
        "    return idx"
      ],
      "id": "40a9c2660445b78c",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:30:56.399874Z",
          "start_time": "2025-04-20T10:30:55.660994Z"
        },
        "id": "22a98021f476cc4d"
      },
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "def text_to_token_ids(text,tokenizer):\n",
        "    encoded=tokenizer.encode(text,allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor=torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "def token_ids_to_text(token_ids,tokenizer):\n",
        "    flat=token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())"
      ],
      "id": "22a98021f476cc4d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c34f6594f2501fd3"
      },
      "cell_type": "markdown",
      "source": [
        "Coding up the Attention model:- Here we would be creating a class of the causal attention and instantiating multiple times for the multihead attention model."
      ],
      "id": "c34f6594f2501fd3"
    },
    {
      "metadata": {
        "id": "779103be54de3305"
      },
      "cell_type": "markdown",
      "source": [
        "Now for example if we set the number of heads we want is 10, then what exactly happens:-\n",
        "--> we obtain a tensor with ten sets of context vector matrices.\n",
        "--> In each context vector matrix the rows represent the context vectors corresponding to the tokens, and the columns corresponding to the embedding dimension specified via d_out.\n",
        "--> Final embedding dimension is 10 x 10."
      ],
      "id": "779103be54de3305"
    },
    {
      "metadata": {
        "id": "55a1ded1a5143e4b"
      },
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTING THE PARALLEL METHOD OF IMPLEMENTATION."
      ],
      "id": "55a1ded1a5143e4b"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:00.004231Z",
          "start_time": "2025-04-20T10:30:59.989116Z"
        },
        "id": "9ffdb4830dd6536c"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            'mask',\n",
        "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec"
      ],
      "id": "9ffdb4830dd6536c",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:03.321536Z",
          "start_time": "2025-04-20T10:31:03.313914Z"
        },
        "id": "4f7ad555c6c06399"
      },
      "cell_type": "code",
      "source": [
        "#Defining the parameters\n",
        "GPT_CONFIG={\n",
        "    'vocab_size':50257,\n",
        "    'context_length':256, # Change it to 1024 or greater if we have gpu\n",
        "    'embedding_dim':512,\n",
        "    'num_heads':16,\n",
        "    'n_layers':12,\n",
        "    'dropout':0.1,\n",
        "    'qkv_bias':False #Whether to include a bias layer in the linear layers of the multi head attention for query,key and value computations.\n",
        "}"
      ],
      "id": "4f7ad555c6c06399",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "47e51a02ecec92d5"
      },
      "cell_type": "markdown",
      "source": [
        "Coding up the placeholder architecture, it is like the mothership from where all the robots will branch out"
      ],
      "id": "47e51a02ecec92d5"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:06.415202Z",
          "start_time": "2025-04-20T10:31:06.403427Z"
        },
        "id": "4bb79e5ab1baf62a"
      },
      "cell_type": "code",
      "source": [
        "class GPT_Model(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        #The __init__ constructor of this GPTModel class initializes the token and positional embedding layers using the configurations passed in via a Python dictionary, cfg.\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"embedding_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"embedding_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"dropout\"])\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "        )\n",
        "        self.final_norm = LayerNormalization(cfg[\"embedding_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"embedding_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "    def forward(self,in_idx):\n",
        "        batch_size,seq_len=in_idx.shape\n",
        "        #in_idx = torch.clamp(in_idx, 0, self.tok_emb.num_embeddings - 1)\n",
        "        token_embeddings=self.tok_emb(in_idx)\n",
        "        positions = torch.arange(seq_len, device=in_idx.device).unsqueeze(0) #this is the extra added line\n",
        "        positional_embeddings=self.pos_emb(positions)\n",
        "        x=token_embeddings+positional_embeddings\n",
        "        x=self.drop_emb(x)\n",
        "        x=self.trf_blocks(x)\n",
        "        x=self.final_norm(x)\n",
        "        logits=self.out_head(x)\n",
        "        return logits"
      ],
      "id": "4bb79e5ab1baf62a",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:09.094024Z",
          "start_time": "2025-04-20T10:31:09.082533Z"
        },
        "id": "b81d6de9cdc325eb"
      },
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self,config):\n",
        "        super().__init__()\n",
        "        self.att=MultiHeadAttention(\n",
        "            d_in=config[\"embedding_dim\"],\n",
        "            d_out=config[\"embedding_dim\"],\n",
        "            context_length=config['context_length'],\n",
        "            dropout=config['dropout'],\n",
        "            num_heads=config['num_heads'],\n",
        "            qkv_bias=config['qkv_bias']\n",
        "        )\n",
        "        self.ff=FeedForward(config)\n",
        "        self.norm1=LayerNormalization(config[\"embedding_dim\"])\n",
        "        self.norm2=LayerNormalization(config[\"embedding_dim\"])\n",
        "        self.drop_resid=nn.Dropout(config['dropout'])\n",
        "    def forward(self,x):\n",
        "        shortcut=x\n",
        "        x=self.norm1(x)\n",
        "        x=self.att(x)\n",
        "        x=self.drop_resid(x)\n",
        "        x=x+shortcut\n",
        "        shortcut=x\n",
        "        x=self.norm2(x)\n",
        "        x=self.ff(x)\n",
        "        x=self.drop_resid(x)\n",
        "        x=x+shortcut\n",
        "        return x"
      ],
      "id": "b81d6de9cdc325eb",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:11.879811Z",
          "start_time": "2025-04-20T10:31:11.869246Z"
        },
        "id": "3f60825a05698f50"
      },
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "    def forward(self,x):\n",
        "        mean= x.mean(-1, keepdim=True)\n",
        "        variance = x.var(-1, keepdim=True)\n",
        "        norm_x=(x-mean)/(torch.sqrt(variance+self.eps))\n",
        "        return self.scale*norm_x + self.shift"
      ],
      "id": "3f60825a05698f50",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ee7086fdb0d258aa"
      },
      "cell_type": "markdown",
      "source": [
        "We will use swish activation function."
      ],
      "id": "ee7086fdb0d258aa"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:14.198107Z",
          "start_time": "2025-04-20T10:31:14.183061Z"
        },
        "id": "aafae17704f79949"
      },
      "cell_type": "code",
      "source": [
        "class Swish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Swish, self).__init__()\n",
        "    def forward(self, x):\n",
        "        return x * torch.sigmoid(x)"
      ],
      "id": "aafae17704f79949",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:16.572707Z",
          "start_time": "2025-04-20T10:31:16.567278Z"
        },
        "id": "4b3a9eeaf0282a32"
      },
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.layers=nn.Sequential(\n",
        "            nn.Linear(config[\"embedding_dim\"], 4*config[\"embedding_dim\"]),\n",
        "            Swish(),\n",
        "            nn.Linear(4*config[\"embedding_dim\"], config[\"embedding_dim\"]),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "id": "4b3a9eeaf0282a32",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:37.956131Z",
          "start_time": "2025-04-20T10:31:37.943199Z"
        },
        "id": "3888c877e7bb59fa"
      },
      "cell_type": "code",
      "source": [
        "class DeepNeuralNetwork(nn.Module):\n",
        "    def __init__(self, layer_sizes,use_shortcut):\n",
        "        super().__init__()\n",
        "        self.layers=nn.ModuleList([\n",
        "            #We would be implementing 10 layers\n",
        "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[5], layer_sizes[6])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[6], layer_sizes[7])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[7], layer_sizes[8])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[8], layer_sizes[9])),\n",
        "            nn.Sequential(nn.Linear(layer_sizes[9], layer_sizes[10])),\n",
        "        ])\n",
        "    def forward(self,x):\n",
        "        for layer in self.layers:\n",
        "            #Computing the output of the current layer\n",
        "            layer_output=layer(x)\n",
        "            #Check if shortcut can be applied\n",
        "            if self.use_shortcut and x.shape==layer_output.shape:\n",
        "                x=x+layer_output\n",
        "            else:\n",
        "                x=layer_output\n",
        "            return x\n",
        "def print_gradients(model,x):\n",
        "    #First would be the forward pass\n",
        "    output = model(x)\n",
        "    target=torch.tensor([0,])\n",
        "    #Loss calculation\n",
        "    loss=nn.MSELoss()\n",
        "    loss=loss(output,target)\n",
        "    loss.backward()\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            print(f\"{name} grad: {param.grad}\")"
      ],
      "id": "3888c877e7bb59fa",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "78ab409a0177825"
      },
      "cell_type": "markdown",
      "source": [
        "Now let us initialise"
      ],
      "id": "78ab409a0177825"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:41.037621Z",
          "start_time": "2025-04-20T10:31:40.974254Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6710dda1f52d8b41",
        "outputId": "c2753e89-89dc-4c5b-c086-53132aded738"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 2  # Number of samples in the batch\n",
        "sequence_length = 10  # Length of each sequence\n",
        "vocab_size = 100  # Size of the vocabulary\n",
        "batch = torch.randint(0, vocab_size, (batch_size, sequence_length))\n",
        "print(batch)"
      ],
      "id": "6710dda1f52d8b41",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[44, 53, 61, 15,  9, 70, 67, 46, 79,  5],\n",
            "        [76, 60, 56, 92, 14, 14, 53, 15, 44, 27]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:44.349704Z",
          "start_time": "2025-04-20T10:31:43.391715Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b376992b9eb9a68c",
        "outputId": "f67dc607-f218-4c20-848d-47212f38b749"
      },
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model=GPT_Model(GPT_CONFIG)\n",
        "out=model(batch)\n",
        "print(\"Input batch:\\n\",batch)\n",
        "print(\"Output batch:\\n\",out.shape)\n",
        "print(out)"
      ],
      "id": "b376992b9eb9a68c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[44, 53, 61, 15,  9, 70, 67, 46, 79,  5],\n",
            "        [76, 60, 56, 92, 14, 14, 53, 15, 44, 27]])\n",
            "Output batch:\n",
            " torch.Size([2, 10, 50000])\n",
            "tensor([[[ 0.4678, -0.5511, -0.5683,  ...,  1.4707,  1.3414,  0.3417],\n",
            "         [ 0.7936,  0.7604,  0.0037,  ..., -0.1304,  0.0257,  0.4613],\n",
            "         [ 0.4322,  0.3863, -0.3351,  ..., -0.5346,  1.2010,  0.4920],\n",
            "         ...,\n",
            "         [ 0.8807, -0.1948, -0.3523,  ..., -0.4180,  0.6709, -0.4552],\n",
            "         [ 0.2633,  0.5850,  0.1626,  ..., -1.2413,  0.3800,  0.1911],\n",
            "         [ 0.9222,  0.3679, -0.4887,  ...,  0.3828,  0.5291,  1.5582]],\n",
            "\n",
            "        [[ 0.6132, -0.1044,  0.3924,  ...,  0.6008,  0.3865,  0.8070],\n",
            "         [ 0.5212,  0.3173,  0.0860,  ...,  0.1296,  0.2347,  0.3906],\n",
            "         [ 0.0695, -0.3108, -0.2167,  ...,  0.3888,  0.4980, -0.1511],\n",
            "         ...,\n",
            "         [-0.3946, -0.0402,  0.5788,  ..., -0.0052,  0.2615,  0.1750],\n",
            "         [-0.1209,  0.1735,  0.3235,  ..., -0.9687,  0.3305, -0.2390],\n",
            "         [ 0.6061,  0.4015,  0.3973,  ...,  0.0887,  0.2874,  0.6616]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "32204ab3e2917ca1"
      },
      "cell_type": "markdown",
      "source": [
        "Displaying the number of parameters for the GPT model"
      ],
      "id": "32204ab3e2917ca1"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:49.707504Z",
          "start_time": "2025-04-20T10:31:49.699751Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfd0d944c222bfbf",
        "outputId": "bbad64e6-f379-475e-80d5-6d3fe5e79824"
      },
      "cell_type": "code",
      "source": [
        "total_parameters=sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_parameters}\")\n",
        "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
        "print(\"Output layer shape:\", model.out_head.weight.shape)"
      ],
      "id": "bfd0d944c222bfbf",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 89142272\n",
            "Token embedding layer shape: torch.Size([50000, 512])\n",
            "Output layer shape: torch.Size([50000, 512])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c2b39710a7897efb"
      },
      "cell_type": "markdown",
      "source": [
        "Number of trainable parameters in the model"
      ],
      "id": "c2b39710a7897efb"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:53.034490Z",
          "start_time": "2025-04-20T10:31:53.027104Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e047e3f5d5b4e540",
        "outputId": "b1793806-df53-4cf2-a09d-52e8485bb35f"
      },
      "cell_type": "code",
      "source": [
        "total_params_gpt2 = total_parameters - sum(p.numel() for p in model.out_head.parameters())\n",
        "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2}\")"
      ],
      "id": "e047e3f5d5b4e540",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable parameters considering weight tying: 63542272\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:31:57.287950Z",
          "start_time": "2025-04-20T10:31:57.279346Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f611c62fb559142f",
        "outputId": "24b7ef8b-df10-40a3-b192-46a8d32cf3e3"
      },
      "cell_type": "code",
      "source": [
        "total_size_in_bytes=total_parameters*4\n",
        "\n",
        "total_size_of_the_model_in_MB=total_size_in_bytes/(1024*1024)\n",
        "print(f\"Total size of the model : {total_size_of_the_model_in_MB:.2f} MB\")"
      ],
      "id": "f611c62fb559142f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total size of the model : 340.05 MB\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "645fa9c01a21b0e3"
      },
      "cell_type": "markdown",
      "source": [
        "Total size of the model : 341.55 MB\n",
        "Number of trainable parameters considering weight tying: 63935488\n"
      ],
      "id": "645fa9c01a21b0e3"
    },
    {
      "metadata": {
        "id": "e32325eb6463fa21"
      },
      "cell_type": "markdown",
      "source": [
        "The next step is to now decode these tensors to proper text. Which would be coding up in the subsequent steps"
      ],
      "id": "e32325eb6463fa21"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:36:18.521800Z",
          "start_time": "2025-04-20T10:36:18.507080Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af8f873de4b1ea1f",
        "outputId": "8761b2e0-af06-4027-fc7b-b09c306d69cf"
      },
      "cell_type": "code",
      "source": [
        "#Let us try out the decoding procedure\n",
        "start_context=\"Hello, I am Aditya.\"\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "encoded=tokenizer.encode(start_context)\n",
        "print(encoded)"
      ],
      "id": "af8f873de4b1ea1f",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9906, 11, 358, 1097, 2467, 488, 64, 13]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:32:31.432690Z",
          "start_time": "2025-04-20T10:32:31.416839Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baf2d02c627a5911",
        "outputId": "b6a59155-048a-49e4-c1b5-683dbbad8f0a"
      },
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "id": "baf2d02c627a5911",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT_Model(\n",
              "  (tok_emb): Embedding(50000, 512)\n",
              "  (pos_emb): Embedding(256, 512)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_key): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (W_value): Linear(in_features=512, out_features=512, bias=False)\n",
              "        (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): Swish()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNormalization()\n",
              "  (out_head): Linear(in_features=512, out_features=50000, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:36:21.766425Z",
          "start_time": "2025-04-20T10:36:21.340642Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e6a5e5afc3272d6",
        "outputId": "4b2dcdff-161f-47c8-cca4-e84a9e117e2f"
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "out=generate_text(model=model,idx=torch.tensor(encoded).unsqueeze(0),max_new_tokens=6,context_size=GPT_CONFIG[\"context_length\"])\n",
        "print(\"Output:\\n\",out)"
      ],
      "id": "8e6a5e5afc3272d6",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            " tensor([[ 9906,    11,   358,  1097,  2467,   488,    64,    13,  2163,  8019,\n",
            "          7580, 20329, 32731,    25]])\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-04-20T10:36:31.970156Z",
          "start_time": "2025-04-20T10:36:30.980631Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ffca81eb2e208dd",
        "outputId": "5d1b6fe6-0368-46c9-ead1-7cc1a3174322"
      },
      "cell_type": "code",
      "source": [
        "start_context=\"Hello, I am Aditya I want to become a CEO one day of my own company\"\n",
        "token_ids=generate_text(model=model,idx=text_to_token_ids(start_context,tokenizer),max_new_tokens=10,context_size=GPT_CONFIG[\"context_length\"])\n",
        "print(\"Output text:\\n\",token_ids_to_text(token_ids,tokenizer))"
      ],
      "id": "1ffca81eb2e208dd",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Hello, I am Aditya I want to become a CEO one day of my own companyPub.bukkitregistry(fields [[ ErrorMessageoptional Send thereleg\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=torch.tensor([[ 9906,    11,   358,  1097,  2467,   488,    64,    13, 41867, 40540,\n",
        "         15145, 30876, 46468, 30001]])  # Remove extra comma and parenthesis to make it a tensor\n",
        "with torch.no_grad():\n",
        "  logits=model(inputs)\n",
        "probas=torch.softmax(logits,dim=-1)\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxZH4QzR-ydZ",
        "outputId": "d46883fa-15f6-44e9-d69f-797a3af7a8c4"
      },
      "id": "yxZH4QzR-ydZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 14, 50000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "train_loader=create_dataloader_v1(train_text,batch_size=2,max_length=GPT_CONFIG[\"context_length\"],\n",
        "                                  stride=GPT_CONFIG['context_length'],\n",
        "                                  drop_last=True,\n",
        "                                  shuffle=True\n",
        "                                  )\n",
        "val_loader=create_dataloader_v1(val_text,batch_size=2,max_length=GPT_CONFIG[\"context_length\"],\n",
        "                                  stride=GPT_CONFIG['context_length'],\n",
        "                                  drop_last=True,\n",
        "                                  shuffle=True\n",
        "                                  )"
      ],
      "metadata": {
        "id": "MTItfymWGhRZ"
      },
      "id": "MTItfymWGhRZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculation_of_loss(input_batch,target_batch,model,device):\n",
        "  input_batch,target_batch=input_batch.to(device),target_batch.to(device)\n",
        "  logits=model(input_batch)\n",
        "  loss=torch.nn.functional.cross_entropy(logits.flatten(0,1),target_batch.flatten())\n",
        "  return loss"
      ],
      "metadata": {
        "id": "Df2uwuFnmOp3"
      },
      "id": "Df2uwuFnmOp3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_loader(data_loader,model,device,num_batches=10):\n",
        "  total_loss=0\n",
        "  num_batches=min(num_batches,len(data_loader))\n",
        "  for i,(input_batch,target_batch) in enumerate(data_loader):\n",
        "    if i<num_batches:\n",
        "      loss=calculation_of_loss(input_batch,target_batch,model,device)\n",
        "      total_loss+=loss.item()\n",
        "    else:\n",
        "      break\n",
        "  return total_loss/num_batches"
      ],
      "metadata": {
        "id": "hdoiK6MLcrYV"
      },
      "id": "hdoiK6MLcrYV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device='cpu'\n",
        "model.to(device)\n",
        "train_loss=loss_loader(train_loader,model,device)\n",
        "val_loss=loss_loader(val_loader,model,device)\n",
        "print(f\"Train loss: {train_loss:.4f}\")\n",
        "print(f\"Validation loss: {val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "x89QUR65ePEs",
        "outputId": "7b4bc307-b3fb-45b7-d067-724481f7bbce"
      },
      "id": "x89QUR65ePEs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index out of range in self",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-5b43a989de4b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train loss: {train_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-5668574f73f5>\u001b[0m in \u001b[0;36mloss_loader\u001b[0;34m(data_loader, model, device, num_batches)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcalculation_of_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mtotal_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-f4f61d0b2dbf>\u001b[0m in \u001b[0;36mcalculation_of_loss\u001b[0;34m(input_batch, target_batch, model, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculation_of_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-257fcdef1a77>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in_idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this is the extra added line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mpositional_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}